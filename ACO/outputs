        File Input Format Counters
                Bytes Read=285
18/12/10 08:46:19 INFO mapred.LocalJobRunner: Finishing task: attempt_local1207862962_0001_m_000000_0
18/12/10 08:46:19 INFO mapred.LocalJobRunner: map task executor complete.
18/12/10 08:46:19 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/12/10 08:46:19 INFO mapred.LocalJobRunner: Starting task: attempt_local1207862962_0001_r_000000_0
18/12/10 08:46:19 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 08:46:19 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 08:46:19 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 08:46:19 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f762581
18/12/10 08:46:19 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/12/10 08:46:19 INFO reduce.EventFetcher: attempt_local1207862962_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/12/10 08:46:19 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1207862962_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
18/12/10 08:46:19 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1207862962_0001_m_000000_0
18/12/10 08:46:19 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
18/12/10 08:46:19 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/12/10 08:46:19 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 08:46:19 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
18/12/10 08:46:19 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 08:46:19 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
18/12/10 08:46:19 INFO reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
18/12/10 08:46:19 INFO reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
18/12/10 08:46:19 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/12/10 08:46:19 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 08:46:19 INFO mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
18/12/10 08:46:19 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 08:46:19 INFO mapred.Task: Task:attempt_local1207862962_0001_r_000000_0 is done. And is in the process of committing18/12/10 08:46:19 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 08:46:19 INFO mapred.Task: Task attempt_local1207862962_0001_r_000000_0 is allowed to commit now
18/12/10 08:46:19 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1207862962_0001_r_000000_0' to file:/home/ywang/outputC/_temporary/0/task_local1207862962_0001_r_000000
18/12/10 08:46:19 INFO mapred.LocalJobRunner: reduce > reduce
18/12/10 08:46:19 INFO mapred.Task: Task 'attempt_local1207862962_0001_r_000000_0' done.
18/12/10 08:46:19 INFO mapred.Task: Final Counters for attempt_local1207862962_0001_r_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=8528
                FILE: Number of bytes written=377487
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=0
                Reduce shuffle bytes=6
                Reduce input records=0
                Reduce output records=0
                Spilled Records=0
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=257425408
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=8
18/12/10 08:46:19 INFO mapred.LocalJobRunner: Finishing task: attempt_local1207862962_0001_r_000000_0
18/12/10 08:46:19 INFO mapred.LocalJobRunner: reduce task executor complete.
18/12/10 08:46:20 INFO mapreduce.Job:  map 100% reduce 100%
18/12/10 08:46:20 INFO mapreduce.Job: Job job_local1207862962_0001 completed successfully
18/12/10 08:46:20 INFO mapreduce.Job: Counters: 30
        File System Counters
                FILE: Number of bytes read=17012
                FILE: Number of bytes written=754960
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=0
                Map output bytes=0
                Map output materialized bytes=6
                Input split bytes=89
                Combine input records=0
                Combine output records=0
                Reduce input groups=0
                Reduce shuffle bytes=6
                Reduce input records=0
                Reduce output records=0
                Spilled Records=0
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=514850816
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=285
        File Output Format Counters
                Bytes Written=8
Elapsed time = 6375 ms
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  rm Main_C/*
zsh: sure you want to delete all 5 files in /home/ywang/aco/Main_C [yn]? y
 ~/aco  ./compile.sh Main
mkdir: cannot create directory ‘Main_C’: File exists
added manifest
adding: Main$Map$ACO.class(in = 5548) (out= 3219)(deflated 41%)
adding: Main$Map$Randoms.class(in = 2040) (out= 1304)(deflated 36%)
adding: Main$Map.class(in = 2730) (out= 1306)(deflated 52%)
adding: Main$Reduce.class(in = 1919) (out= 837)(deflated 56%)
adding: Main.class(in = 1810) (out= 911)(deflated 49%)
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  hadoop jar Main.jar Main input ~/outputC
18/12/10 09:14:18 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/12/10 09:14:18 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/12/10 09:14:18 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
Exception in thread "main" org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/ywang/outputC already exists
        at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
        at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:270)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:141)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
        at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:575)
        at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:570)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:570)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:561)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:870)
        at Main.main(Main.java:43)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
 ✘  ~/aco  hadoop jar Main.jar Main input output
18/12/10 09:14:33 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/12/10 09:14:33 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/12/10 09:14:33 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
18/12/10 09:14:33 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/12/10 09:14:33 INFO mapred.FileInputFormat: Total input files to process : 1
18/12/10 09:14:33 INFO mapreduce.JobSubmitter: number of splits:1
18/12/10 09:14:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2014050070_0001
18/12/10 09:14:34 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/12/10 09:14:34 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/12/10 09:14:34 INFO mapreduce.Job: Running job: job_local2014050070_0001
18/12/10 09:14:34 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
18/12/10 09:14:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:14:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:14:34 INFO mapred.LocalJobRunner: Waiting for map tasks
18/12/10 09:14:34 INFO mapred.LocalJobRunner: Starting task: attempt_local2014050070_0001_m_000000_0
18/12/10 09:14:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:14:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:14:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:14:34 INFO mapred.MapTask: Processing split: file:/home/ywang/aco/input/cities.txt:0+285
18/12/10 09:14:34 INFO mapred.MapTask: numReduceTasks: 1
18/12/10 09:14:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/12/10 09:14:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/12/10 09:14:34 INFO mapred.MapTask: soft limit at 83886080
18/12/10 09:14:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/12/10 09:14:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/12/10 09:14:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/12/10 09:14:35 INFO mapreduce.Job: Job job_local2014050070_0001 running in uber mode : false
18/12/10 09:14:35 INFO mapreduce.Job:  map 0% reduce 0%
BEST ROUTE:
source
670.1514759037999 source V1Y5CWSMPQBDR3GXK96IO7LAF84NTUEZH20J

length: 670.1514759037999
18/12/10 09:14:38 INFO mapred.LocalJobRunner:
18/12/10 09:14:38 INFO mapred.MapTask: Starting flush of map output
18/12/10 09:14:38 INFO mapred.MapTask: Spilling map output
18/12/10 09:14:38 INFO mapred.MapTask: bufstart = 0; bufend = 69; bufvoid = 104857600
18/12/10 09:14:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
18/12/10 09:14:38 INFO mapred.MapTask: Finished spill 0
18/12/10 09:14:38 INFO mapred.Task: Task:attempt_local2014050070_0001_m_000000_0 is done. And is in the process of committing18/12/10 09:14:38 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/cities.txt:0+285
18/12/10 09:14:38 INFO mapred.Task: Task 'attempt_local2014050070_0001_m_000000_0' done.
18/12/10 09:14:38 INFO mapred.Task: Final Counters for attempt_local2014050070_0001_m_000000_0: Counters: 17
        File System Counters
                FILE: Number of bytes read=8971
                FILE: Number of bytes written=378041
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=1
                Map output bytes=69
                Map output materialized bytes=77
                Input split bytes=89
                Combine input records=0
                Spilled Records=1
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=257425408
        File Input Format Counters
                Bytes Read=285
18/12/10 09:14:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local2014050070_0001_m_000000_0
18/12/10 09:14:38 INFO mapred.LocalJobRunner: map task executor complete.
18/12/10 09:14:38 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/12/10 09:14:38 INFO mapred.LocalJobRunner: Starting task: attempt_local2014050070_0001_r_000000_0
18/12/10 09:14:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:14:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:14:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:14:38 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15c10832
18/12/10 09:14:38 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/12/10 09:14:38 INFO reduce.EventFetcher: attempt_local2014050070_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/12/10 09:14:38 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2014050070_0001_m_000000_0 decomp: 73 len: 77 to MEMORY
18/12/10 09:14:38 INFO reduce.InMemoryMapOutput: Read 73 bytes from map-output for attempt_local2014050070_0001_m_000000_0
18/12/10 09:14:38 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 73, inMemoryMapOutputs.size() -> 1,
commitMemory -> 0, usedMemory ->73
18/12/10 09:14:38 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/12/10 09:14:38 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 09:14:38 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
18/12/10 09:14:38 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 09:14:38 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64 bytes
18/12/10 09:14:38 INFO reduce.MergeManagerImpl: Merged 1 segments, 73 bytes to disk to satisfy reduce memory limit
18/12/10 09:14:38 INFO reduce.MergeManagerImpl: Merging 1 files, 77 bytes from disk
18/12/10 09:14:38 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/12/10 09:14:38 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 09:14:38 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64 bytes
18/12/10 09:14:38 INFO mapred.LocalJobRunner: 1 / 1 copied.

!!!!!!!!!!!!!!!!!REDUCER!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

670.1514759037999
18/12/10 09:14:38 INFO mapred.Task: Task:attempt_local2014050070_0001_r_000000_0 is done. And is in the process of committing18/12/10 09:14:38 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 09:14:38 INFO mapred.Task: Task attempt_local2014050070_0001_r_000000_0 is allowed to commit now
18/12/10 09:14:38 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2014050070_0001_r_000000_0' to file:/home/ywang/aco/output/_temporary/0/task_local2014050070_0001_r_000000
18/12/10 09:14:38 INFO mapred.LocalJobRunner: reduce > reduce
18/12/10 09:14:38 INFO mapred.Task: Task 'attempt_local2014050070_0001_r_000000_0' done.
18/12/10 09:14:38 INFO mapred.Task: Final Counters for attempt_local2014050070_0001_r_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=9157
                FILE: Number of bytes written=378126
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=77
                Reduce input records=1
                Reduce output records=0
                Spilled Records=1
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=257425408
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=8
18/12/10 09:14:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local2014050070_0001_r_000000_0
18/12/10 09:14:38 INFO mapred.LocalJobRunner: reduce task executor complete.
18/12/10 09:14:39 INFO mapreduce.Job:  map 100% reduce 100%
18/12/10 09:14:39 INFO mapreduce.Job: Job job_local2014050070_0001 completed successfully
18/12/10 09:14:39 INFO mapreduce.Job: Counters: 30
        File System Counters
                FILE: Number of bytes read=18128
                FILE: Number of bytes written=756167
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=1
                Map output bytes=69
                Map output materialized bytes=77
                Input split bytes=89
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=77
                Reduce input records=1
                Reduce output records=0
                Spilled Records=2
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=514850816
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=285
        File Output Format Counters
                Bytes Written=8
Elapsed time = 6761 ms
 ~/aco 
 ✘  ~/aco 
 ✘  ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input  output
 ~/aco  rm Main.jar
 ~/aco  rm -r Main_C output
 ~/aco  ls
ACO.java  Main.java  Randoms.java  compile.sh  input
 ~/aco  ./compile.sh Main
added manifest
adding: Main$Map$ACO.class(in = 5548) (out= 3219)(deflated 41%)
adding: Main$Map$Randoms.class(in = 2040) (out= 1304)(deflated 36%)
adding: Main$Map.class(in = 2728) (out= 1304)(deflated 52%)
adding: Main$Reduce.class(in = 1970) (out= 886)(deflated 55%)
adding: Main.class(in = 1810) (out= 911)(deflated 49%)
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  cd input
 ~/aco/input  ls
cities.txt
 ~/aco/input  cp cities.txt c1 c2
cp: target 'c2' is not a directory
 ✘  ~/aco/input  ls
cities.txt
 ~/aco/input  cp cities.txt ./c1
 ~/aco/input  ls
c1  cities.txt
 ~/aco/input  cp c1 ./c2 ./c3
cp: target './c3' is not a directory
 ✘  ~/aco/input  ls
c1  cities.txt
 ~/aco/input  cp
cp: missing file operand
Try 'cp --help' for more information.
 ✘  ~/aco/input  cd --help
cd: no such file or directory: --help
 ✘  ~/aco/input  cp --help
Usage: cp [OPTION]... [-T] SOURCE DEST
  or:  cp [OPTION]... SOURCE... DIRECTORY
  or:  cp [OPTION]... -t DIRECTORY SOURCE...
Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY.

Mandatory arguments to long options are mandatory for short options too.
  -a, --archive                same as -dR --preserve=all
      --attributes-only        don't copy the file data, just the attributes
      --backup[=CONTROL]       make a backup of each existing destination file
  -b                           like --backup but does not accept an argument
      --copy-contents          copy contents of special files when recursive
  -d                           same as --no-dereference --preserve=links
  -f, --force                  if an existing destination file cannot be
                                 opened, remove it and try again (this option
                                 is ignored when the -n option is also used)
  -i, --interactive            prompt before overwrite (overrides a previous -n
                                  option)
  -H                           follow command-line symbolic links in SOURCE
  -l, --link                   hard link files instead of copying
  -L, --dereference            always follow symbolic links in SOURCE
  -n, --no-clobber             do not overwrite an existing file (overrides
                                 a previous -i option)
  -P, --no-dereference         never follow symbolic links in SOURCE
  -p                           same as --preserve=mode,ownership,timestamps
      --preserve[=ATTR_LIST]   preserve the specified attributes (default:
                                 mode,ownership,timestamps), if possible
                                 additional attributes: context, links, xattr,
                                 all
      --no-preserve=ATTR_LIST  don't preserve the specified attributes
      --parents                use full source file name under DIRECTORY
  -R, -r, --recursive          copy directories recursively
      --reflink[=WHEN]         control clone/CoW copies. See below
      --remove-destination     remove each existing destination file before
                                 attempting to open it (contrast with --force)
      --sparse=WHEN            control creation of sparse files. See below
      --strip-trailing-slashes  remove any trailing slashes from each SOURCE
                                 argument
  -s, --symbolic-link          make symbolic links instead of copying
  -S, --suffix=SUFFIX          override the usual backup suffix
  -t, --target-directory=DIRECTORY  copy all SOURCE arguments into DIRECTORY
  -T, --no-target-directory    treat DEST as a normal file
  -u, --update                 copy only when the SOURCE file is newer
                                 than the destination file or when the
                                 destination file is missing
  -v, --verbose                explain what is being done
  -x, --one-file-system        stay on this file system
  -Z                           set SELinux security context of destination
                                 file to default type
      --context[=CTX]          like -Z, or if CTX is specified then set the
                                 SELinux or SMACK security context to CTX
      --help     display this help and exit
      --version  output version information and exit

By default, sparse SOURCE files are detected by a crude heuristic and the
corresponding DEST file is made sparse as well.  That is the behavior
selected by --sparse=auto.  Specify --sparse=always to create a sparse DEST
file whenever the SOURCE file contains a long enough sequence of zero bytes.
Use --sparse=never to inhibit creation of sparse files.

When --reflink[=always] is specified, perform a lightweight copy, where the
data blocks are copied only when modified.  If this is not possible the copy
fails, or if --reflink=auto is specified, fall back to a standard copy.

The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX.
The version control method may be selected via the --backup option or through
the VERSION_CONTROL environment variable.  Here are the values:

  none, off       never make backups (even if --backup is given)
  numbered, t     make numbered backups
  existing, nil   numbered if numbered backups exist, simple otherwise
  simple, never   always make simple backups

As a special case, cp makes a backup of SOURCE when the force and backup
options are given and SOURCE and DEST are the same name for an existing,
regular file.

GNU coreutils online help: <http://www.gnu.org/software/coreutils/>
Report cp translation bugs to <http://translationproject.org/team/>
Full documentation at: <http://www.gnu.org/software/coreutils/cp>
or available locally via: info '(coreutils) cp invocation'
 ~/aco/input  cp c1 ./c3
 ~/aco/input  cp c1 ./c4
 ~/aco/input  ls
c1  c3  c4  cities.txt
 ~/aco/input  cd ../
 ~/aco  l
total 48K
drwxrwxrwx 1 ywang ywang 4.0K Dec 10 01:19 .
drwxr-xr-x 1 ywang ywang 4.0K Dec 10 01:20 ..
-rwxrwxrwx 1 ywang ywang 8.3K Dec 10 00:32 ACO.java
-rw-rw-rw- 1 ywang ywang 8.4K Dec 10 01:19 Main.jar
-rwxrwxrwx 1 ywang ywang  16K Dec 10 01:18 Main.java
drwxrwxrwx 1 ywang ywang 4.0K Dec 10 01:19 Main_C
-rwxrwxrwx 1 ywang ywang 3.2K Dec 10 00:32 Randoms.java
-rwxrwxrwx 1 ywang ywang   89 Dec 10 00:34 compile.sh
drwxrwxrwx 1 ywang ywang 4.0K Dec 10 01:20 input
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  hadoop jar Main.jar Main input output
18/12/10 09:21:03 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/12/10 09:21:03 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/12/10 09:21:03 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
18/12/10 09:21:03 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/12/10 09:21:03 INFO mapred.FileInputFormat: Total input files to process : 4
18/12/10 09:21:03 INFO mapreduce.JobSubmitter: number of splits:4
18/12/10 09:21:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local745239886_0001
18/12/10 09:21:03 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/12/10 09:21:03 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/12/10 09:21:03 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
18/12/10 09:21:03 INFO mapreduce.Job: Running job: job_local745239886_0001
18/12/10 09:21:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:21:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:21:03 INFO mapred.LocalJobRunner: Waiting for map tasks
18/12/10 09:21:03 INFO mapred.LocalJobRunner: Starting task: attempt_local745239886_0001_m_000000_0
18/12/10 09:21:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:21:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:21:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:21:04 INFO mapred.MapTask: Processing split: file:/home/ywang/aco/input/c1:0+285
18/12/10 09:21:04 INFO mapred.MapTask: numReduceTasks: 1
18/12/10 09:21:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/12/10 09:21:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/12/10 09:21:04 INFO mapred.MapTask: soft limit at 83886080
18/12/10 09:21:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/12/10 09:21:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/12/10 09:21:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/12/10 09:21:04 INFO mapreduce.Job: Job job_local745239886_0001 running in uber mode : false
18/12/10 09:21:04 INFO mapreduce.Job:  map 0% reduce 0%
18/12/10 09:21:16 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285 > map
18/12/10 09:21:16 INFO mapreduce.Job:  map 17% reduce 0%
^C%
 ✘  ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input  output
 ~/aco  cd input
 ~/aco/input  ls
c1  c3  c4  cities.txt
 ~/aco/input  rm c2
rm: cannot remove 'c2': No such file or directory
 ✘  ~/aco/input  rm c3
 ~/aco/input  rm c4 cities.txt
 ~/aco/input  cat c1
source 0 0 A 26 68 B 81 57 C 88 15 D 69 64 E 58 25 F 17 60 G 1 69 H 58 5 I 16 24 J 43 40 K 12 60 L 32 64 M 91 38 N 3 51 O 17
28 P 94 43 Q 97 75 R 52 85 S 90 21 T 1 48 U 46 19 V 8 0 W 88 19 X 5 57 Y 43 0 Z 49 7 0 61 33 1 23 4 2 71 27 3 55 88 4 7 49 5
83 4 6 24 35 7 42 66 8 8 43 9 15 55%
 ~/aco/input  cat c1
source 0 0 A 26 68 B 81 57 C 88 15 D 69 64 E 58 25 F 17 60 G 1 69 H 58 5 I 16 24 J 43 40 K 12 60 L 32 64 M 91 38 N 3 51 O 17
28 P 94 43 Q 97 75 R 52 85 S 90 21 T 1 48 U 46 19 V 8 0 W 88 19 X 5 57 Y 43 0 Z 49 7 0 61 33 1 23 4 2 71 27 3 55 88 4 7 49 5
83 4 6 24 35 7 42 66 8 8 43 9 15 55%
 ~/aco/input  cd
 ~  ls
aco  compile.sh  outputC  prog3
 ~  cd aco
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input  output
 ~/aco  rm -r output
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  hadoop jar Main.jar Main input output
18/12/10 09:25:27 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/12/10 09:25:27 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/12/10 09:25:27 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
18/12/10 09:25:27 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/12/10 09:25:27 INFO mapred.FileInputFormat: Total input files to process : 1
18/12/10 09:25:27 INFO mapreduce.JobSubmitter: number of splits:1
18/12/10 09:25:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local871284086_0001
18/12/10 09:25:28 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/12/10 09:25:28 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/12/10 09:25:28 INFO mapreduce.Job: Running job: job_local871284086_0001
18/12/10 09:25:28 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
18/12/10 09:25:28 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:25:28 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:25:28 INFO mapred.LocalJobRunner: Waiting for map tasks
18/12/10 09:25:28 INFO mapred.LocalJobRunner: Starting task: attempt_local871284086_0001_m_000000_0
18/12/10 09:25:28 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:25:28 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:25:28 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:25:28 INFO mapred.MapTask: Processing split: file:/home/ywang/aco/input/c1:0+285
18/12/10 09:25:28 INFO mapred.MapTask: numReduceTasks: 1
18/12/10 09:25:28 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/12/10 09:25:28 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/12/10 09:25:28 INFO mapred.MapTask: soft limit at 83886080
18/12/10 09:25:28 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/12/10 09:25:28 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/12/10 09:25:28 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/12/10 09:25:29 INFO mapreduce.Job: Job job_local871284086_0001 running in uber mode : false
18/12/10 09:25:29 INFO mapreduce.Job:  map 0% reduce 0%
18/12/10 09:25:40 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285 > map
18/12/10 09:25:41 INFO mapreduce.Job:  map 67% reduce 0%
^C%
 ✘  ~/aco 
 ✘  ~/aco 
 ✘  ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input  output
 ~/aco  rm Main_C
rm: cannot remove 'Main_C': Is a directory
 ✘  ~/aco  rm -r Main_C output
 ~/aco  ls
ACO.java  Main.jar  Main.java  Randoms.java  compile.sh  input
 ~/aco  ./compile.sh Main
added manifest
adding: Main$Map$ACO.class(in = 5548) (out= 3219)(deflated 41%)
adding: Main$Map$Randoms.class(in = 2040) (out= 1304)(deflated 36%)
adding: Main$Map.class(in = 2730) (out= 1304)(deflated 52%)
adding: Main$Reduce.class(in = 1970) (out= 886)(deflated 55%)
adding: Main.class(in = 1810) (out= 911)(deflated 49%)
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  cd input
 ~/aco/input  ls
c1
 ~/aco/input  cd ../
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  hadoop jar Main.jar Main input output
18/12/10 09:29:01 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/12/10 09:29:01 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/12/10 09:29:01 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
18/12/10 09:29:01 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/12/10 09:29:02 INFO mapred.FileInputFormat: Total input files to process : 1
18/12/10 09:29:02 INFO mapreduce.JobSubmitter: number of splits:1
18/12/10 09:29:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1940720198_0001
18/12/10 09:29:02 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/12/10 09:29:02 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/12/10 09:29:02 INFO mapreduce.Job: Running job: job_local1940720198_0001
18/12/10 09:29:02 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
18/12/10 09:29:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:29:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:29:02 INFO mapred.LocalJobRunner: Waiting for map tasks
18/12/10 09:29:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1940720198_0001_m_000000_0
18/12/10 09:29:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:29:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:29:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:29:02 INFO mapred.MapTask: Processing split: file:/home/ywang/aco/input/c1:0+285
18/12/10 09:29:02 INFO mapred.MapTask: numReduceTasks: 1
18/12/10 09:29:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/12/10 09:29:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/12/10 09:29:02 INFO mapred.MapTask: soft limit at 83886080
18/12/10 09:29:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/12/10 09:29:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/12/10 09:29:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/12/10 09:29:03 INFO mapreduce.Job: Job job_local1940720198_0001 running in uber mode : false
18/12/10 09:29:03 INFO mapreduce.Job:  map 0% reduce 0%
18/12/10 09:29:14 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285 > map
18/12/10 09:29:15 INFO mapreduce.Job:  map 67% reduce 0%
BEST ROUTE:
source
615.4789314751833 source V1OIZHEUJ684NXTGF9KAL7R3BDQPMW5CS20Y

length: 615.4789314751833
18/12/10 09:29:53 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285 > map
18/12/10 09:29:53 INFO mapred.MapTask: Starting flush of map output
18/12/10 09:29:53 INFO mapred.MapTask: Spilling map output
18/12/10 09:29:53 INFO mapred.MapTask: bufstart = 0; bufend = 69; bufvoid = 104857600
18/12/10 09:29:53 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
18/12/10 09:29:53 INFO mapred.MapTask: Finished spill 0
18/12/10 09:29:53 INFO mapred.Task: Task:attempt_local1940720198_0001_m_000000_0 is done. And is in the process of committing18/12/10 09:29:53 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285
18/12/10 09:29:53 INFO mapred.Task: Task 'attempt_local1940720198_0001_m_000000_0' done.
18/12/10 09:29:53 INFO mapred.Task: Final Counters for attempt_local1940720198_0001_m_000000_0: Counters: 17
        File System Counters
                FILE: Number of bytes read=9010
                FILE: Number of bytes written=378080
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=1
                Map output bytes=69
                Map output materialized bytes=77
                Input split bytes=81
                Combine input records=0
                Spilled Records=1
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=257425408
        File Input Format Counters
                Bytes Read=285
18/12/10 09:29:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local1940720198_0001_m_000000_0
18/12/10 09:29:53 INFO mapred.LocalJobRunner: map task executor complete.
18/12/10 09:29:53 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/12/10 09:29:53 INFO mapred.LocalJobRunner: Starting task: attempt_local1940720198_0001_r_000000_0
18/12/10 09:29:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:29:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:29:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:29:53 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a1725e9
18/12/10 09:29:53 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/12/10 09:29:53 INFO reduce.EventFetcher: attempt_local1940720198_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/12/10 09:29:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1940720198_0001_m_000000_0 decomp: 73 len: 77 to MEMORY
18/12/10 09:29:53 INFO reduce.InMemoryMapOutput: Read 73 bytes from map-output for attempt_local1940720198_0001_m_000000_0
18/12/10 09:29:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 73, inMemoryMapOutputs.size() -> 1,
commitMemory -> 0, usedMemory ->73
18/12/10 09:29:53 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/12/10 09:29:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 09:29:53 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
18/12/10 09:29:53 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 09:29:53 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64 bytes
18/12/10 09:29:53 INFO reduce.MergeManagerImpl: Merged 1 segments, 73 bytes to disk to satisfy reduce memory limit
18/12/10 09:29:53 INFO reduce.MergeManagerImpl: Merging 1 files, 77 bytes from disk
18/12/10 09:29:53 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/12/10 09:29:53 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 09:29:53 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 64 bytes
18/12/10 09:29:53 INFO mapred.LocalJobRunner: 1 / 1 copied.

!!!!!!!!!!!!!!!!!REDUCER!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

615.4789314751833 source V1OIZHEUJ684NXTGF9KAL7R3BDQPMW5CS20Y
18/12/10 09:29:53 INFO mapred.Task: Task:attempt_local1940720198_0001_r_000000_0 is done. And is in the process of committing18/12/10 09:29:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/12/10 09:29:53 INFO mapred.Task: Task attempt_local1940720198_0001_r_000000_0 is allowed to commit now
18/12/10 09:29:53 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1940720198_0001_r_000000_0' to file:/home/ywang/aco/output/_temporary/0/task_local1940720198_0001_r_000000
18/12/10 09:29:53 INFO mapred.LocalJobRunner: reduce > reduce
18/12/10 09:29:53 INFO mapred.Task: Task 'attempt_local1940720198_0001_r_000000_0' done.
18/12/10 09:29:53 INFO mapred.Task: Final Counters for attempt_local1940720198_0001_r_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=9196
                FILE: Number of bytes written=378165
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=77
                Reduce input records=1
                Reduce output records=0
                Spilled Records=1
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=257425408
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=8
18/12/10 09:29:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local1940720198_0001_r_000000_0
18/12/10 09:29:53 INFO mapred.LocalJobRunner: reduce task executor complete.
18/12/10 09:29:53 INFO mapreduce.Job:  map 100% reduce 100%
18/12/10 09:29:53 INFO mapreduce.Job: Job job_local1940720198_0001 completed successfully
18/12/10 09:29:53 INFO mapreduce.Job: Counters: 30
        File System Counters
                FILE: Number of bytes read=18206
                FILE: Number of bytes written=756245
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=1
                Map output bytes=69
                Map output materialized bytes=77
                Input split bytes=81
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=77
                Reduce input records=1
                Reduce output records=0
                Spilled Records=2
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=514850816
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=285
        File Output Format Counters
                Bytes Written=8
Elapsed time = 52664 ms
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input  output
 ~/aco  rm -r output
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  cd input
 ~/aco/input  ls
c1
 ~/aco/input  cp c1 ./c2
 ~/aco/input  ls
c1  c2
 ~/aco/input  cd ../
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  ls
ACO.java  Main.jar  Main.java  Main_C  Randoms.java  compile.sh  input
 ~/aco  rm -r Main_C
 ~/aco  ./compile.sh Main
added manifest
adding: Main$Map$ACO.class(in = 5548) (out= 3219)(deflated 41%)
adding: Main$Map$Randoms.class(in = 2040) (out= 1304)(deflated 36%)
adding: Main$Map.class(in = 2728) (out= 1304)(deflated 52%)
adding: Main$Reduce.class(in = 1970) (out= 886)(deflated 55%)
adding: Main.class(in = 1810) (out= 911)(deflated 49%)
 ~/aco  hadoop jar Main.jar Main input output
18/12/10 09:32:25 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/12/10 09:32:25 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/12/10 09:32:25 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
18/12/10 09:32:25 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/12/10 09:32:26 INFO mapred.FileInputFormat: Total input files to process : 2
18/12/10 09:32:26 INFO mapreduce.JobSubmitter: number of splits:2
18/12/10 09:32:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1385404720_0001
18/12/10 09:32:26 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/12/10 09:32:26 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/12/10 09:32:26 INFO mapreduce.Job: Running job: job_local1385404720_0001
18/12/10 09:32:26 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
18/12/10 09:32:26 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:32:26 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:32:26 INFO mapred.LocalJobRunner: Waiting for map tasks
18/12/10 09:32:26 INFO mapred.LocalJobRunner: Starting task: attempt_local1385404720_0001_m_000000_0
18/12/10 09:32:26 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:32:26 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:32:26 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:32:26 INFO mapred.MapTask: Processing split: file:/home/ywang/aco/input/c1:0+285
18/12/10 09:32:26 INFO mapred.MapTask: numReduceTasks: 1
18/12/10 09:32:26 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/12/10 09:32:26 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/12/10 09:32:26 INFO mapred.MapTask: soft limit at 83886080
18/12/10 09:32:26 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/12/10 09:32:26 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/12/10 09:32:26 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/12/10 09:32:27 INFO mapreduce.Job: Job job_local1385404720_0001 running in uber mode : false
18/12/10 09:32:27 INFO mapreduce.Job:  map 0% reduce 0%
18/12/10 09:32:38 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285 > map
18/12/10 09:32:39 INFO mapreduce.Job:  map 33% reduce 0%
BEST ROUTE:
source
569.1484736822905 source V1O6I8TN4XG9KFAL7R3QDBPMCWS52J0EHZYU

length: 569.1484736822905
18/12/10 09:40:51 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285 > map
18/12/10 09:40:51 INFO mapred.MapTask: Starting flush of map output
18/12/10 09:40:51 INFO mapred.MapTask: Spilling map output
18/12/10 09:40:51 INFO mapred.MapTask: bufstart = 0; bufend = 69; bufvoid = 104857600
18/12/10 09:40:51 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
18/12/10 09:40:51 INFO mapred.MapTask: Finished spill 0
18/12/10 09:40:51 INFO mapred.Task: Task:attempt_local1385404720_0001_m_000000_0 is done. And is in the process of committing18/12/10 09:40:51 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c1:0+285
18/12/10 09:40:51 INFO mapred.Task: Task 'attempt_local1385404720_0001_m_000000_0' done.
18/12/10 09:40:51 INFO mapred.Task: Final Counters for attempt_local1385404720_0001_m_000000_0: Counters: 17
        File System Counters
                FILE: Number of bytes read=9106
                FILE: Number of bytes written=378176
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=1
                Map output bytes=69
                Map output materialized bytes=77
                Input split bytes=81
                Combine input records=0
                Spilled Records=1
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=257425408
        File Input Format Counters
                Bytes Read=285
18/12/10 09:40:51 INFO mapred.LocalJobRunner: Finishing task: attempt_local1385404720_0001_m_000000_0
18/12/10 09:40:51 INFO mapred.LocalJobRunner: Starting task: attempt_local1385404720_0001_m_000001_0
18/12/10 09:40:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:40:51 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:40:51 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:40:51 INFO mapred.MapTask: Processing split: file:/home/ywang/aco/input/c2:0+285
18/12/10 09:40:51 INFO mapred.MapTask: numReduceTasks: 1
18/12/10 09:40:52 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/12/10 09:40:52 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/12/10 09:40:52 INFO mapred.MapTask: soft limit at 83886080
18/12/10 09:40:52 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/12/10 09:40:52 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/12/10 09:40:52 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/12/10 09:40:52 INFO mapreduce.Job:  map 100% reduce 0%
18/12/10 09:41:03 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c2:0+285 > map
18/12/10 09:41:04 INFO mapreduce.Job:  map 83% reduce 0%
BEST ROUTE:
source
569.1484736822905 source V1O6I8TN4XG9KFAL7R3QDBPMCWS52J0EHZYU

length: 569.1484736822905
18/12/10 09:49:24 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c2:0+285 > map
18/12/10 09:49:24 INFO mapred.MapTask: Starting flush of map output
18/12/10 09:49:24 INFO mapred.MapTask: Spilling map output
18/12/10 09:49:24 INFO mapred.MapTask: bufstart = 0; bufend = 69; bufvoid = 104857600
18/12/10 09:49:24 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
18/12/10 09:49:24 INFO mapred.MapTask: Finished spill 0
18/12/10 09:49:24 INFO mapred.Task: Task:attempt_local1385404720_0001_m_000001_0 is done. And is in the process of committing18/12/10 09:49:24 INFO mapred.LocalJobRunner: file:/home/ywang/aco/input/c2:0+285
18/12/10 09:49:24 INFO mapred.Task: Task 'attempt_local1385404720_0001_m_000001_0' done.
18/12/10 09:49:24 INFO mapred.Task: Final Counters for attempt_local1385404720_0001_m_000001_0: Counters: 17
        File System Counters
                FILE: Number of bytes read=9572
                FILE: Number of bytes written=378285
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=1
                Map output records=1
                Map output bytes=69
                Map output materialized bytes=77
                Input split bytes=81
                Combine input records=0
                Spilled Records=1
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=362807296
        File Input Format Counters
                Bytes Read=285
18/12/10 09:49:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local1385404720_0001_m_000001_0
18/12/10 09:49:24 INFO mapred.LocalJobRunner: map task executor complete.
18/12/10 09:49:24 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/12/10 09:49:24 INFO mapred.LocalJobRunner: Starting task: attempt_local1385404720_0001_r_000000_0
18/12/10 09:49:24 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/12/10 09:49:24 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/12/10 09:49:24 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/12/10 09:49:24 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@40c28098
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/12/10 09:49:24 INFO reduce.EventFetcher: attempt_local1385404720_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/12/10 09:49:24 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1385404720_0001_m_000000_0 decomp: 73 len: 77 to MEMORY
18/12/10 09:49:24 INFO reduce.InMemoryMapOutput: Read 73 bytes from map-output for attempt_local1385404720_0001_m_000000_0
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 73, inMemoryMapOutputs.size() -> 1,
commitMemory -> 0, usedMemory ->73
18/12/10 09:49:24 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1385404720_0001_m_000001_0 decomp: 73 len: 77 to MEMORY
18/12/10 09:49:24 INFO reduce.InMemoryMapOutput: Read 73 bytes from map-output for attempt_local1385404720_0001_m_000001_0
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 73, inMemoryMapOutputs.size() -> 2,
commitMemory -> 73, usedMemory ->146
18/12/10 09:49:24 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/12/10 09:49:24 INFO mapred.LocalJobRunner: 2 / 2 copied.
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
18/12/10 09:49:24 INFO mapred.Merger: Merging 2 sorted segments
18/12/10 09:49:24 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 128 bytes
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: Merged 2 segments, 146 bytes to disk to satisfy reduce memory limit
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: Merging 1 files, 148 bytes from disk
18/12/10 09:49:24 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/12/10 09:49:24 INFO mapred.Merger: Merging 1 sorted segments
18/12/10 09:49:24 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 135 bytes
18/12/10 09:49:24 INFO mapred.LocalJobRunner: 2 / 2 copied.

!!!!!!!!!!!!!!!!!REDUCER!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

569.1484736822905 source V1O6I8TN4XG9KFAL7R3QDBPMCWS52J0EHZYU
18/12/10 09:49:24 INFO mapred.Task: Task:attempt_local1385404720_0001_r_000000_0 is done. And is in the process of committing18/12/10 09:49:24 INFO mapred.LocalJobRunner: 2 / 2 copied.
18/12/10 09:49:24 INFO mapred.Task: Task attempt_local1385404720_0001_r_000000_0 is allowed to commit now
18/12/10 09:49:24 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1385404720_0001_r_000000_0' to file:/home/ywang/aco/output/_temporary/0/task_local1385404720_0001_r_000000
18/12/10 09:49:24 INFO mapred.LocalJobRunner: reduce > reduce
18/12/10 09:49:24 INFO mapred.Task: Task 'attempt_local1385404720_0001_r_000000_0' done.
18/12/10 09:49:24 INFO mapred.Task: Final Counters for attempt_local1385404720_0001_r_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=9938
                FILE: Number of bytes written=378441
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=154
                Reduce input records=2
                Reduce output records=0
                Spilled Records=2
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=7
                Total committed heap usage (bytes)=362807296
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=8
18/12/10 09:49:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local1385404720_0001_r_000000_0
18/12/10 09:49:24 INFO mapred.LocalJobRunner: reduce task executor complete.
18/12/10 09:49:24 INFO mapreduce.Job:  map 100% reduce 100%
18/12/10 09:49:25 INFO mapreduce.Job: Job job_local1385404720_0001 completed successfully
18/12/10 09:49:25 INFO mapreduce.Job: Counters: 30
        File System Counters
                FILE: Number of bytes read=28616
                FILE: Number of bytes written=1134902
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=2
                Map output records=2
                Map output bytes=138
                Map output materialized bytes=154
                Input split bytes=162
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=154
                Reduce input records=2
                Reduce output records=0
                Spilled Records=4
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=7
                Total committed heap usage (bytes)=983040000
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=570
        File Output Format Counters
                Bytes Written=8
Elapsed time = 1021092 ms